# ğŸ™ï¸ Whisper.Mojo

A high-performance implementation of OpenAI's **Whisper** model (Tiny version) written entirely in **Mojo** ğŸ”¥.

## ğŸš€ Overview

This project brings the power of OpenAI's Whisper to the Mojo programming language. By implementing the architecture from the ground up, we leverage Mojo's unique ability to combine Python-like syntax with C-level performance through hardware acceleration, SIMD, and low-level memory control.

> [!NOTE] 
> This implementation currently supports **Whisper-Tiny** with greedy decoding for English transcription.

## âœ¨ Features

- **ğŸ¯ Pure Mojo Implementation**: Every layer (Encoder, Decoder, Multi-Head Attention) is written in Mojo.
- **âš¡ SIMD Acceleration**: Core tensor operations (Matmul, LayerNorm, GeLU) are vectorized using Mojo's SIMD primitives.
- **ğŸ§ Real-world Audio**: Integrated pipeline to process real audio files (MP3/WAV) into Mel spectrograms.
- **ğŸ” Bit-Perfect Tokenization**: Fully compatible with OpenAI's tokenizer, producing identical results to the PyTorch reference implementation.
- **ğŸ’ª Memory Efficient**: Manual memory management using `LegacyUnsafePointer` for maximum control.

## ğŸ“‚ Project Structure

| File | Description |
| :--- | :--- |
| `main.mojo` | ğŸ® The entry point. Orchestrates weight loading, audio processing, and transcription. |
| `whisper.mojo` | ğŸ§  The "Brain". Contains the `Whisper` model, `Encoder`, and `Decoder` logic. |
| `layers.mojo` | ğŸ§± Core building blocks: `MultiHeadAttention` and `ResidualAttentionBlock`. |
| `whisper_tensor.mojo` | ğŸ§¬ Mathematical foundation. Implements `Tensor` and operations like `matmul`, `conv1d`, and `softmax`. |
| `tokenizer.mojo` | ğŸ”¤ Decodes the model's numeric output (token IDs) back into human-readable text. |
| `loader.mojo` | ğŸ“¥ Efficiently loads model weights from a binary format into Mojo Tensors. |
| `export_weights.py` | ğŸ Python bridge. Handles model downloading, weight exporting, and audio preprocessing. |
| `vocab.txt` | ğŸ“š The vocabulary file used for decoding tokens. |

## ğŸ› ï¸ Getting Started

### ğŸ“‹ Prerequisites

- **Mojo SDK** (v24.5+)
- **Python Environment** (for weight export) with:
  - `torch`, `transformers`, `soundfile`, `scipy`, `requests`

### ğŸ—ï¸ Installation & Execution

1. **Clone & Setup**
   ```bash
   git clone https://github.com/antonvice/whisper.Mojo.git
   cd whisper.Mojo
   ```

2. **Export Weights & Prepare Audio**
   This script downloads the Whisper-Tiny weights and converts a sample audio file into a format Mojo can read.
   ```bash
   uv run export_weights.py
   ```

3. **Run Transcription**
   Launch the Mojo model to transcribe the prepared audio:
   ```bash
   mojo run main.mojo
   ```

## ğŸ“Š Performance Note

You might notice that `mojo run main.mojo` takes a few moments to execute. This is primarily because:
1. **JIT Compilation**: `mojo run` compiles the code on-the-fly. For production speed, use `mojo build main.mojo` to create a standalone binary.
2. **Current Optimization**: This is a reference implementation. While it uses SIMD for matmuls, many other loops (like the Attention scores) are currently single-threaded. Future versions will implement `parallelize` and tiling for even greater speeds.

## ğŸ“ Example Output

```text
Initializing Whisper Tiny in Mojo...
Loading weights from whisper_tiny_weights.bin...
Transcription:
--------------------
 This is my voice on the left. This is my voice on the left hand side...
--------------------
```

## ğŸ“œ License

This project is licensed under the MIT License - see the LICENSE file for details.
